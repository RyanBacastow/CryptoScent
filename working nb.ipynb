{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What words would you like to search for?\n",
      "ripple\n",
      "How many tweets would you like me to filter through?\n",
      "200\n",
      "xrp100%upって凄い！\n",
      "\n",
      "リップラーおめでとうございます\n",
      "\n",
      "#xrp\n",
      "#ripple\n",
      "#リップル\n",
      "#リップラ\n",
      "#仮想通貨pic.twitter.com/XBuFIFMysc \n",
      "\n",
      "#XRP holders, hope you are wearing you sealt belt, launch to the moon has been iniated \n",
      "#RIPPLE #xrpthestandard \n",
      "\n",
      "\"Buy the rumor, sell the news\". \n",
      "\n",
      "If you sell the news about Coinbase, you will regret for the rest of your life! #Ripple $XRP  \n",
      "\n",
      "Thats why xrp will rule the world in 2018 \n",
      "\n",
      "@Ripple XRP blows past 3+ Billion volume USD in the last 24 hours! #Ripple #XRP #XRPtheStandardpic.twitter.com/J0S8kENTXG \n",
      "\n",
      "#xrp #ripple #bitstamp ITS HAPPENING!!https://twitter.com/bgarlinghouse/status/941375649549246464 … \n",
      "\n",
      "Ripple to the moon!\n",
      "And for now the announcements scheduled tomorrow Friday have not yet been unveiled! \n",
      "Tomorrow is going to be a big day for  @Ripple and for us!\n",
      "#ripple #xrp #ripplexrp #CryptocurrencyNews #Cryptocurency #cryptocurrencies #cryptos #Crypto #ToTheMoonpic.twitter.com/nGZwsJlWJO \n",
      "\n",
      "Invested at 0.25 now almost at $1. Buy Ripple https://twitter.com/bgarlinghouse/status/941375649549246464 … \n",
      "\n",
      "Ripple’s XRP overtakes bitcoin cash as 3rd largest cryptocurrency https://buff.ly/2Bpdsby pic.twitter.com/vV3QiiDOcu \n",
      "\n",
      "Great work!  Especially the amount of fires they put out when some investors were bugging out.  For us that held, seems to be paying off!  \n",
      "\n",
      "എല്ലാരും ripple വാങ്ങി മരിക്കുന്നു. ബിറ്റ് ഇടിയുന്നു. \n",
      "\n",
      "トコトン振り回してくれるrippleちゃん…でも好き！！！ \n",
      "\n",
      "BITCOIN:\n",
      "Slow AF.\n",
      "\n",
      "RIPPLE:\n",
      "Fast and easy.\n",
      "\n",
      "It's not differential calculus, folks.\n",
      "\n",
      "#BTC\n",
      "#XRP \n",
      "\n",
      "Haha, ripple went on a rampage. So much FOMO. \n",
      "\n",
      "My entire feed is talking about Ripple. The alt bull cycle has begun. \n",
      "\n",
      "Es sind dutzende banken eine Partnerschaft mit ripple eingegangen sogar die bill gates foundation arbeitet bei denen mit dein szenario ist ungefähr so wahrscheinlich wie dass die ezb aufhört geld zu drucken \n",
      "\n",
      "Best crew #xrp #xrpthestandard #ripple https://twitter.com/yankeefx/status/941376112457912320 … \n",
      "\n",
      "Ripple’s XRP overtakes bitcoin cash as 3rd largest cryptocurrency Graham Rapier pic.twitter.com/ruZQynQYPB \n",
      "\n",
      "Ripple logra el 3er puesto en Coinmarketcap con una capitalización de de más de 34.57 Billones de dólares. GO GO GO \n",
      "#RIPPLE\n",
      "#XRP\n",
      "#ripple #xrp\n",
      "#cryptocurrency\n",
      "#criptomonedas \n",
      "\n",
      "Your file is saved as ripple_2017-12-14_12_55_20.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import codecs\n",
    "import json\n",
    "from twitterscraper import query_tweets\n",
    "from twitterscraper.query import query_all_tweets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "def main():\n",
    "    keyword = input(\"What words would you like to search for?\\n\")\n",
    "    number = int(input(\"How many tweets would you like me to filter through?\\n\"))\n",
    "    fname = '{}_{}.json'.format(keyword, str(datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")))\n",
    "    query = 'twitterscraper {} -l {} -o {}'.format(keyword, number,fname)\n",
    "    os.system(query)\n",
    "    with codecs.open(fname,'r','utf-8') as f:\n",
    "        tweets = json.load(f, encoding='utf-8')\n",
    "        for tweet in tweets:\n",
    "            if int(tweet['likes'])> 1 or int(tweet['retweets']) > 1:\n",
    "                print(tweet['text'],'\\n')\n",
    "        df.append([tweet['text']])\n",
    "    print(\"Your file is saved as {}\".format(fname))\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitter import *\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pdb\n",
    "import twitter\n",
    "\n",
    "def oauth_login():\n",
    "    # XXX: Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = '3vhPtpq5VjXpz1SVh3z2nc1Gu'\n",
    "    CONSUMER_SECRET = 'vW223v1O7537APiEsPq2U52oLsqtcZMEZzoSoHanBE6hIiQo9U'\n",
    "    OAUTH_TOKEN = '941412073392701442-x7cBQoqEx8g81iRj2BlqQ5sIz9MNHbT'\n",
    "    OAUTH_TOKEN_SECRET = 'NiWLPN8lfPa7GOGwbQ8TetlqWVp7JFf1XXHbuUoq0c1Tz'\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "\n",
    "# Twitter search function to get a number of tweets using a search query\n",
    "def TwitterSearch(twitterApi, query, approxCount = 3000, **kw):\n",
    "    search = input('How many results should I return to you?')\n",
    "    searchResults = twitterApi.search.tweets(q= query, count=search, **kw)\n",
    "    statuses = searchResults['statuses']\n",
    "    while len(statuses) < approxCount:\n",
    "        try:\n",
    "            nextResults = searchResults['search_metadata']['next_results']\n",
    "        except KeyError as e:\n",
    "            break\n",
    "        print( str(len(statuses)) + ' results have been downloaded from approximately ' + str(approxCount))\n",
    "        kwargs = dict([ kv.split('=') for kv in nextResults[1:].split(\"&\") ])\n",
    "        nextResults = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += nextResults['statuses'] # cool append notation\n",
    "        print( 'A total of ' + str(len(statuses)) + ' have been downloaded')\n",
    "    return statuses\n",
    "             \n",
    "dir= \"r'{}'\".format(os.getcwd())\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "q = input(\"What would you like to search? \\n\")\n",
    "\n",
    "status = TwitterSearch(twitter_api, q, approxCount = 2000)\n",
    "status2 = TwitterSearch(twitter_api, q, approxCount = 2000)\n",
    "statuses= status + status2\n",
    "        \n",
    "# # Show one sample search status by slicing the list...\n",
    "# print( json.dumps(statuses[0], indent=1))\n",
    "\n",
    "\n",
    "# for _ in range(30):\n",
    "\t# print( \"Length of statuses\", len(statuses))\n",
    "\t# try:\n",
    "\t\t# next_statuses = search_statuses['search_metadata']['next_statuses']\n",
    "\t# except KeyError, e: # No more statuses when next_statuses doesn't exist\n",
    "\t\t# break\n",
    "\n",
    "# kwargs = dict([ kv.split('=') for kv in next_statuses[1:].split(\"&\") ])\n",
    "# search_statuses = twitter_api.search.tweets(**kwargs)\n",
    "\n",
    "status_id = [status['id'] for status in statuses ]\n",
    "name = [status['user']['name'] for status in statuses ]\n",
    "screen_name = [status['user']['screen_name'] for status in statuses ]\n",
    "status_text = [status['text'] for status in statuses ]\n",
    "location = [status['user']['location'] for status in statuses ]\n",
    "geo = [status['geo']for status in statuses ]\n",
    "time_zone = [status['user']['time_zone']for status in statuses ]\n",
    "friend_count =  [status['user']['friends_count'] for status in statuses]\n",
    "follower_count = [status['user']['followers_count'] for status in statuses]\n",
    "tmstamp = [status['created_at'] for status in statuses]\n",
    "retweet_ct = [status['retweet_count'] for status in statuses]\n",
    "source = [status['source'] for status in statuses]\n",
    "place = [status['place'] for status in statuses]\n",
    "data = {'status_id' : status_id,\n",
    "        'name' : name,\n",
    "        'screen_name' : screen_name,\n",
    "        'status_text' : status_text,\n",
    "        'tmstamp' : tmstamp,\n",
    "        'time_zone' : time_zone,\n",
    "        'location' : location,\n",
    "        'geo' : geo,\n",
    "        'friend_count' : friend_count,\n",
    "        'follower_count' : follower_count,\n",
    "        'retweet_count' : retweet_ct,\n",
    "        'source' : source,\n",
    "        'place' : place}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(dir + r + str(time.strftime(\"%d_%m_%Y\")) + '.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
